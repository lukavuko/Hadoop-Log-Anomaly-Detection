{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Pad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalous: 4 / 158336\n"
     ]
    }
   ],
   "source": [
    "## Import Data\n",
    "\n",
    "# sequence column lists are in string format so use literal eval to reconvert\n",
    "all_event_sequence = pd.read_csv('../Data/OpenStack/all_event_sequences.csv', header=0, index_col=None, converters={\"sequence\": literal_eval})\n",
    "kmeans_event_sequence = pd.read_csv('../Data/OpenStack/kmean_event_sequences.csv', header=0, index_col=None, converters={\"sequence\": literal_eval})\n",
    "\n",
    "# Anomaly Labels (Response)\n",
    "labels = all_event_sequence['anomaly']\n",
    "\n",
    "print(f'Anomalous: {sum(labels)} / {len(labels)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sequence', ylabel='Count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# view length of sequences\n",
    "lens = all_event_sequence.sequence.apply(lambda x: len(x))\n",
    "\n",
    "sns.histplot(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalous: 4 / 2067\n"
     ]
    }
   ],
   "source": [
    "## remove single sequences (they're not sequences)\n",
    "all_event_sequence = all_event_sequence.loc[lens > 2, :].reset_index(drop = True)\n",
    "kmeans_event_sequence = kmeans_event_sequence.loc[lens > 2, :].reset_index(drop = True)\n",
    "\n",
    "# Pad sequences (Predictor)\n",
    "padded_all = pad_sequences(all_event_sequence.sequence, padding='post')\n",
    "padded_km = pad_sequences(kmeans_event_sequence.sequence, padding='post')\n",
    "\n",
    "# new labels\n",
    "labels = all_event_sequence['anomaly']\n",
    "\n",
    "print(f'Anomalous: {sum(labels)} / {len(labels)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.5 (1033)\n",
      "Val: 0.25 (517)\n",
      "Test: 0.25(517)\n",
      "Total: 1 (2067)\n",
      "2 1 1\n"
     ]
    }
   ],
   "source": [
    "# Split Train 0.5\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, train_size = 0.50)\n",
    "for train_index, rest_index in sss.split(padded_all, labels):\n",
    "    x_train, x_other = padded_all[train_index], padded_all[rest_index]\n",
    "    y_train, y_other = labels[train_index], labels[rest_index]\n",
    "\n",
    "# Split Val 0.25 / Test 0.25\n",
    "for val_index, test_index in sss.split(x_other, y_other):\n",
    "    x_val, x_test = padded_all[val_index], padded_all[test_index]\n",
    "    y_val, y_test = labels[val_index], labels[test_index]\n",
    "\n",
    "# Standardize to arrays\n",
    "y_train, y_val, y_test = np.array(y_train), np.array(y_val), np.array(y_test)\n",
    "\n",
    "\n",
    "# Check proportions\n",
    "trn, val, tst = len(y_train), len(y_val), len(y_test)\n",
    "tot = sum([trn, val, tst])\n",
    "print(f'Train: {round(trn/tot, 2)} ({trn})',\n",
    "      f'Val: {round(val/tot, 2)} ({val})',\n",
    "      f'Test: {round(tst/tot, 2)}({tst})',\n",
    "      f'Total: {1} ({tot})', sep = '\\n')\n",
    "\n",
    "print(sum(y_train), sum(y_val), sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dimensions\n",
      "\n",
      "Sequence matrix size: torch.Size([100, 27])\n",
      "Target vector size: torch.Size([100])\n",
      "\n",
      "Sequence matrix size: torch.Size([100, 27])\n",
      "Target vector size: torch.Size([100])\n",
      "\n",
      "Sequence matrix size: torch.Size([100, 27])\n",
      "Target vector size: torch.Size([100])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "\n",
    "################################\n",
    "## Create Tensor Datasets \n",
    "################################\n",
    "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "val_data = TensorDataset(torch.from_numpy(x_val), torch.from_numpy(y_val))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
    "\n",
    "\n",
    "################################\n",
    "## Dataset Iterators:\n",
    "################################\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=BATCH_SIZE, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, pin_memory=True, drop_last=True)\n",
    "\n",
    "print('Training Dimensions\\n')\n",
    "for data_cat in [train_loader, val_loader, test_loader]:\n",
    "    for batch in data_cat:\n",
    "        print(f'Sequence matrix size: {batch[0].size()}')\n",
    "        print(f'Target vector size: {batch[1].size()}\\n')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch LSTM Model\n",
    "And associated functions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Events: 1723\n",
      "Unique Events w kmeans: 10\n"
     ]
    }
   ],
   "source": [
    "# \"vocabulary\" size\n",
    "\n",
    "all_events = all_event_sequence.sequence.apply(pd.Series).stack().reset_index(drop = True)\n",
    "kmean_events = kmeans_event_sequence.sequence.apply(pd.Series).stack().reset_index(drop = True)\n",
    "\n",
    "print('Unique Events:', len(all_events.unique()))\n",
    "print('Unique Events w kmeans:', len(kmean_events.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## ARCHITECTURAL PARAMETERS\n",
    "################################\n",
    "VOCAB_SIZE_all_events = 1723\n",
    "VOCAB_SIZE_kmean_events = 10\n",
    "OUTPUT_SIZE = 1\n",
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "CLIP = 5\n",
    "\n",
    "################################\n",
    "## MODEL\n",
    "################################\n",
    "class Anomaly_Detector(nn.Module):\n",
    "    def __init__(self,  vocab_size, output_size, embedding_dim, hidden_dim, batch_size, n_layers, bidirectinoal=True, drop_prob=0):\n",
    "        super().__init__()\n",
    "\n",
    "        # Params\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.bidir = 2 if bidirectinoal==True else 1\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
    "                            batch_first=True,\n",
    "                            num_layers=n_layers, \n",
    "                            dropout=drop_prob,  \n",
    "                            bidirectional=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim*self.bidir, output_size) # multiply hidden by 2 if using bidirectinoality\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "    def forward(self, sequences): \n",
    "        sequences = sequences.long().to(DEVICE) # [batch_size, seq_len]\n",
    "        embedded = self.dropout(self.embedding(sequences)) # [batch_size, seq_length, embedded_dim]\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded) \n",
    "        # lstm_out = [batch_size, seq_length, hidden_dim * num_directions]\n",
    "        # hidden = [num layers * num directions,  batch size, hidden_dim]\n",
    "        # cell = [num layers * num directions, batch size, hidden_dim]\n",
    "        \n",
    "        if self.bidir==2:\n",
    "            # Concat the final forward and barckward hidden layers + apply dropout if specified\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        elif self.bidir==1: \n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "\n",
    "        out = self.activation(self.fc(hidden).reshape(-1))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "################################\n",
    "## DEFINE ACCURACY FUNCTION\n",
    "################################\n",
    "def compute_binary_accuracy(model, data_loader, device, print_output=False):\n",
    "    model.eval()\n",
    "    all_preds = torch.empty(0).cuda()\n",
    "    all_labs = torch.empty(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inpt, labs in data_loader:\n",
    "\n",
    "            inpt, labs = inpt.cuda(), labs.cuda()\n",
    "            all_labs = torch.cat((all_labs, labs), 0).reshape(-1)\n",
    "\n",
    "            logits = model(inpt)\n",
    "            predicted_labels = (logits > 0.5).reshape(-1)\n",
    "            all_preds = torch.cat((all_preds, predicted_labels), 0).reshape(-1)\n",
    "\n",
    "        # Move to CPU\n",
    "        all_preds, all_labs = all_preds.cpu(), all_labs.cpu()\n",
    "        accuracy = round(accuracy_score(all_labs, all_preds), 4) # of all predictions, how many were correct?\n",
    "        precision = round(precision_score(all_labs, all_preds), 4) # of predicted anomalies, how many were correct?\n",
    "        recall = round(recall_score(all_labs, all_preds), 4) # of all true anomalies, how many were recovered?\n",
    "\n",
    "        if print_output:\n",
    "            print(confusion_matrix(all_labs, all_preds), end = '\\n\\n')\n",
    "            print('Accuracy:', accuracy) \n",
    "            print('Precision:', precision) \n",
    "            print('Recall:', recall)\n",
    "            return None\n",
    "        \n",
    "        return accuracy, precision, recall\n",
    "\n",
    "################################\n",
    "## DEFINE TRAINING + TESTING FUNCTION\n",
    "################################\n",
    "def training_function():\n",
    "    print('\\nSTARTING TRAINING\\n')\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        model.train()\n",
    "        print(f'Current Epoch: {epoch+1}')\n",
    "\n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "\n",
    "            inpt, labs = batch_data[0], batch_data[1].to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad() # Clear gradients from last batch\n",
    "\n",
    "            logits = model(inpt) # Compute logits (ie. final hidden state)\n",
    "\n",
    "            # Compute cost\n",
    "            cost = criterion(logits.squeeze(), labs.float())\n",
    "            cost.backward()\n",
    "\n",
    "            # Use clip_grad_norm to prevent exploding gradients\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log\n",
    "            if not batch_idx % 100:\n",
    "                print (f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                       f'BCE Cost: {cost:.4f}')\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model.eval()\n",
    "            print(f'Epoch Comleted: {epoch+1}'\n",
    "                  f'\\n\\twith training accuracy: {compute_binary_accuracy(model, train_loader, DEVICE)[0]:.4f}%'\n",
    "                  f'\\n\\tand validation accuracy: {compute_binary_accuracy(model, val_loader, DEVICE)[0]:.4f}%')\n",
    "\n",
    "        print(f'\\tTime elapsed: {(time.time() - start_time)/60:.2f} min\\n')\n",
    "\n",
    "    ## Final Test Accuracy\n",
    "    print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "    print('----------------------------------------------')\n",
    "    print('Final Test Accuracy/Precision/Recall : ', compute_binary_accuracy(model, test_loader, DEVICE))\n",
    "    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make models reproducible\n",
    "\n",
    "RANDOM_SEED = 123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Vanilla LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING TRAINING\n",
      "\n",
      "Current Epoch: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at ..\\aten\\src\\THC\\THCCachingHostAllocator.cpp:278",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a29ed60c4d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m## TRAIN/TEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtraining_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-1fff19c3070d>\u001b[0m in \u001b[0;36mtraining_function\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Current Epoch: {epoch+1}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0minpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pin_memory\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pin_memory\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at ..\\aten\\src\\THC\\THCCachingHostAllocator.cpp:278"
     ]
    }
   ],
   "source": [
    "# using vocab of 2000+\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "#torch.manual_seed(RANDOM_SEED)\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 4\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "## INITIALIZE MODEL\n",
    "model = Anomaly_Detector(VOCAB_SIZE_all_events, OUTPUT_SIZE, EMBEDDING_DIM, HIDDEN_DIM, BATCH_SIZE, NUM_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "## LOSS AND OPTIMIZER\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "## TRAIN/TEST\n",
    "training_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at ..\\aten\\src\\THC\\THCCachingHostAllocator.cpp:278",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-90e5b415d995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mcompute_binary_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprint_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-90e5b415d995>\u001b[0m in \u001b[0;36mcompute_binary_accuracy\u001b[1;34m(model, data_loader, device, print_output)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0minpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0minpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pin_memory\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pin_memory\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at ..\\aten\\src\\THC\\THCCachingHostAllocator.cpp:278"
     ]
    }
   ],
   "source": [
    "def compute_binary_accuracy(model, data_loader, device, print_output=False):\n",
    "    model.eval()\n",
    "    all_preds = torch.empty(0).cuda()\n",
    "    all_labs = torch.empty(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inpt, labs in data_loader:\n",
    "\n",
    "            inpt, labs = inpt.cuda(), labs.cuda()\n",
    "            all_labs = torch.cat((all_labs, labs), 0).reshape(-1)\n",
    "\n",
    "            logits = model(inpt)\n",
    "            predicted_labels = (logits > 0.5).reshape(-1)\n",
    "            all_preds = torch.cat((all_preds, predicted_labels), 0).reshape(-1)\n",
    "\n",
    "        # Move to CPU\n",
    "        all_preds, all_labs = all_preds.cpu(), all_labs.cpu()\n",
    "        accuracy = accuracy_score(all_labs, all_preds) # of all predictions, how many were correct?\n",
    "        precision = precision_score(all_labs, all_preds) # of predicted anomalies, how many were correct?\n",
    "        recall = recall_score(all_labs, all_preds) # of all true anomalies, how many were recovered?\n",
    "\n",
    "        if print_output:\n",
    "            print(confusion_matrix(all_labs, all_preds), end = '\\n\\n')\n",
    "            print('Accuracy:', accuracy) \n",
    "            print('Precision:', precision) \n",
    "            print('Recall:', recall)\n",
    "            return None\n",
    "        \n",
    "        return accuracy, precision, recall\n",
    "    \n",
    "compute_binary_accuracy(model, test_loader, DEVICE,print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3faa8f8f8526>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# using vocab of 20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\cuda\\random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[1;34m(callable)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\cuda\\random.py\u001b[0m in \u001b[0;36mcb\u001b[1;34m()\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# using vocab of 20\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 3\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "## INITIALIZE MODEL\n",
    "model = Anomaly_Detector(VOCAB_SIZE_kmean_events, OUTPUT_SIZE, EMBEDDING_DIM, HIDDEN_DIM, BATCH_SIZE, NUM_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "## LOSS AND OPTIMIZER\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "## TRAIN/TEST\n",
    "training_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 2 Layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING TRAINING\n",
      "\n",
      "Current Epoch: 1\n",
      "Batch 000/402 | BCE Cost: 0.6993\n",
      "Batch 100/402 | BCE Cost: 0.0863\n",
      "Batch 200/402 | BCE Cost: 0.1178\n",
      "Batch 300/402 | BCE Cost: 0.0860\n",
      "Batch 400/402 | BCE Cost: 0.0934\n",
      "Epoch Comleted: 1\n",
      "\twith training accuracy: 0.9815%\n",
      "\tand validation accuracy: 0.9808%\n",
      "\tTime elapsed: 1.85 min\n",
      "\n",
      "Current Epoch: 2\n",
      "Batch 000/402 | BCE Cost: 0.0537\n",
      "Batch 100/402 | BCE Cost: 0.0155\n",
      "Batch 200/402 | BCE Cost: 0.0071\n",
      "Batch 300/402 | BCE Cost: 0.0072\n",
      "Batch 400/402 | BCE Cost: 0.0089\n",
      "Epoch Comleted: 2\n",
      "\twith training accuracy: 0.9981%\n",
      "\tand validation accuracy: 0.9982%\n",
      "\tTime elapsed: 3.88 min\n",
      "\n",
      "Current Epoch: 3\n",
      "Batch 000/402 | BCE Cost: 0.0061\n",
      "Batch 100/402 | BCE Cost: 0.0168\n",
      "Batch 200/402 | BCE Cost: 0.0101\n",
      "Batch 300/402 | BCE Cost: 0.0088\n",
      "Batch 400/402 | BCE Cost: 0.0032\n",
      "Epoch Comleted: 3\n",
      "\twith training accuracy: 0.9989%\n",
      "\tand validation accuracy: 0.9990%\n",
      "\tTime elapsed: 5.93 min\n",
      "\n",
      "Total Training Time: 5.93 min\n",
      "----------------------------------------------\n",
      "Final Test Accuracy/Precision/Recall :  (0.9989, 0.9801, 0.9813)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Params: 2 Layer\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 3\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "## INITIALIZE MODEL\n",
    "model = Anomaly_Detector(VOCAB_SIZE, OUTPUT_SIZE, EMBEDDING_DIM, HIDDEN_DIM, BATCH_SIZE, NUM_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "## LOSS AND OPTIMIZER\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "training_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING TRAINING\n",
      "\n",
      "Current Epoch: 1\n",
      "Batch 000/402 | BCE Cost: 0.7502\n",
      "Batch 100/402 | BCE Cost: 0.1390\n",
      "Batch 200/402 | BCE Cost: 0.1049\n",
      "Batch 300/402 | BCE Cost: 0.0787\n",
      "Batch 400/402 | BCE Cost: 0.0833\n",
      "Epoch Comleted: 1\n",
      "\twith training accuracy: 0.9815%\n",
      "\tand validation accuracy: 0.9809%\n",
      "\tTime elapsed: 0.90 min\n",
      "\n",
      "Current Epoch: 2\n",
      "Batch 000/402 | BCE Cost: 0.1048\n",
      "Batch 100/402 | BCE Cost: 0.0760\n",
      "Batch 200/402 | BCE Cost: 0.0169\n",
      "Batch 300/402 | BCE Cost: 0.0080\n",
      "Batch 400/402 | BCE Cost: 0.0135\n",
      "Epoch Comleted: 2\n",
      "\twith training accuracy: 0.9980%\n",
      "\tand validation accuracy: 0.9982%\n",
      "\tTime elapsed: 1.79 min\n",
      "\n",
      "Current Epoch: 3\n",
      "Batch 000/402 | BCE Cost: 0.0170\n",
      "Batch 100/402 | BCE Cost: 0.0036\n",
      "Batch 200/402 | BCE Cost: 0.0027\n",
      "Batch 300/402 | BCE Cost: 0.0169\n",
      "Batch 400/402 | BCE Cost: 0.0020\n",
      "Epoch Comleted: 3\n",
      "\twith training accuracy: 0.9991%\n",
      "\tand validation accuracy: 0.9991%\n",
      "\tTime elapsed: 2.68 min\n",
      "\n",
      "Total Training Time: 2.68 min\n",
      "----------------------------------------------\n",
      "Final Test Accuracy/Precision/Recall :  (0.9991, 0.993, 0.9777)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Params 1 Layer / Bidirectional\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 3\n",
    "NUM_LAYERS = 1\n",
    "DROPOUT = 0\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "## INITIALIZE MODEL\n",
    "model = Anomaly_Detector(VOCAB_SIZE, OUTPUT_SIZE, EMBEDDING_DIM, HIDDEN_DIM, BATCH_SIZE, NUM_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "## LOSS AND OPTIMIZER\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "training_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING TRAINING\n",
      "\n",
      "Current Epoch: 1\n",
      "Batch 000/402 | BCE Cost: 0.7074\n",
      "Batch 100/402 | BCE Cost: 0.0932\n",
      "Batch 200/402 | BCE Cost: 0.1304\n",
      "Batch 300/402 | BCE Cost: 0.0753\n",
      "Batch 400/402 | BCE Cost: 0.0239\n",
      "Epoch Comleted: 1\n",
      "\twith training accuracy: 0.9816%\n",
      "\tand validation accuracy: 0.9813%\n",
      "\tTime elapsed: 2.35 min\n",
      "\n",
      "Current Epoch: 2\n",
      "Batch 000/402 | BCE Cost: 0.0371\n",
      "Batch 100/402 | BCE Cost: 0.0210\n",
      "Batch 200/402 | BCE Cost: 0.0154\n",
      "Batch 300/402 | BCE Cost: 0.0086\n",
      "Batch 400/402 | BCE Cost: 0.0021\n",
      "Epoch Comleted: 2\n",
      "\twith training accuracy: 0.9983%\n",
      "\tand validation accuracy: 0.9982%\n",
      "\tTime elapsed: 4.21 min\n",
      "\n",
      "Current Epoch: 3\n",
      "Batch 000/402 | BCE Cost: 0.0077\n",
      "Batch 100/402 | BCE Cost: 0.0051\n",
      "Batch 200/402 | BCE Cost: 0.0034\n",
      "Batch 300/402 | BCE Cost: 0.0010\n",
      "Batch 400/402 | BCE Cost: 0.0008\n",
      "Epoch Comleted: 3\n",
      "\twith training accuracy: 0.9995%\n",
      "\tand validation accuracy: 0.9996%\n",
      "\tTime elapsed: 6.05 min\n",
      "\n",
      "Total Training Time: 6.05 min\n",
      "----------------------------------------------\n",
      "Final Test Accuracy/Precision/Recall :  (0.9995, 0.9943, 0.9895)\n",
      "----------------------------------------------\n",
      "[[111632     19]\n",
      " [    35   3314]]\n",
      "\n",
      "Accuracy: 0.9995\n",
      "Precision: 0.9943\n",
      "Recall: 0.9895\n"
     ]
    }
   ],
   "source": [
    "# Params: 2 layer / Bidirectional\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 3\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "## INITIALIZE MODEL\n",
    "model = Anomaly_Detector(VOCAB_SIZE, OUTPUT_SIZE, EMBEDDING_DIM, HIDDEN_DIM, BATCH_SIZE, NUM_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "## LOSS AND OPTIMIZER\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "training_function()\n",
    "\n",
    "## See confusion matrix\n",
    "compute_binary_accuracy(model, test_loader, DEVICE, print_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
