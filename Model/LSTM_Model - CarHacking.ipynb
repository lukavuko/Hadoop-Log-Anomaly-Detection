{
 "cells": [
  {
   "source": [
    "## Model Fitting on Sequential Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(199274, 100, 2)\n(199274,)\n"
     ]
    }
   ],
   "source": [
    "## LOAD DATA FROM PICKLE\n",
    "import pickle\n",
    "\n",
    "path = '../Data/HK-CarHackingDataset/'\n",
    "filename1 =  path + 'X'\n",
    "filename2 = path + 'y'\n",
    "\n",
    "with open(filename1,'rb') as f:\n",
    "    X_back = pickle.load(f)\n",
    "    print(X_back.shape)\n",
    "\n",
    "with open(filename2,'rb') as f:\n",
    "    y_back = pickle.load(f)\n",
    "    print(y_back.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train 0.6 / other 0.4\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, train_size = 0.60)\n",
    "for train_index, rest_index in sss.split(X, y):\n",
    "    x_train, x_other = X[train_index, :, :], X[rest_index, :, :]\n",
    "    y_train, y_other = y[train_index], y[rest_index]\n",
    "\n",
    "# split Val 0.2 / Test 0.2\n",
    "sss2 = StratifiedShuffleSplit(n_splits = 1, train_size = 0.50)\n",
    "for val_index, test_index in sss2.split(x_other, y_other):\n",
    "    x_val, x_test = x_other[val_index, :, :], x_other[test_index, :, :]\n",
    "    y_val, y_test = y_other[val_index], y_other[test_index]\n",
    "\n",
    "# Check proportions\n",
    "trn, val, tst = len(y_train), len(y_val), len(y_test)\n",
    "tot = sum([trn, val, tst])\n",
    "\n",
    "print(f'Train: {round(trn/tot, 2)} ({trn})',\n",
    "      f'Val: {round(val/tot, 2)} ({val})',\n",
    "      f'Test: {round(tst/tot, 2)} ({tst})',\n",
    "      f'\\nTotal = {tot}', sep = '\\n')\n",
    "\n",
    "print('Anomalies per group:', sum(y_train), sum(y_val), sum(y_test))"
   ]
  },
  {
   "source": [
    "## Build Data Loaders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "################################\n",
    "## Create Tensor Datasets \n",
    "################################\n",
    "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "val_data = TensorDataset(torch.from_numpy(x_val), torch.from_numpy(y_val))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
    "\n",
    "\n",
    "################################\n",
    "## Dataset Iterators:\n",
    "################################\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=BATCH_SIZE, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=BATCH_SIZE, pin_memory=True, drop_last=True)\n",
    "\n",
    "print('Training Dimensions\\n')\n",
    "for data_cat in [train_loader, val_loader, test_loader]:\n",
    "    for batch in data_cat:\n",
    "        print(f'Sequence matrix size: {batch[0].size()}')\n",
    "        print(f'Target vector size: {batch[1].size()}\\n')\n",
    "        break"
   ]
  },
  {
   "source": [
    "## Multivariate LSTM Network\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## DEFINE ACCURACY FUNCTION\n",
    "################################\n",
    "def compute_binary_accuracy(model, data_loader, device, print_output=False):\n",
    "    model.eval()\n",
    "    all_preds, all_labs= torch.empty(0).to(DEVICE), torch.empty(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inpt, labs in data_loader:\n",
    "            inpt, labs = inpt.float().to(DEVICE), labs.float().to(DEVICE)\n",
    "            all_labs = torch.cat((all_labs, labs), 0).reshape(-1)\n",
    "\n",
    "            logits = model(inpt)\n",
    "            predicted_labels = (logits >= 0.5).reshape(-1)\n",
    "            all_preds = torch.cat((all_preds, predicted_labels), 0).reshape(-1)\n",
    "\n",
    "    # Move to CPU and benchmark\n",
    "    all_preds, all_labs = all_preds.cpu(), all_labs.cpu() \n",
    "    accuracy = round(accuracy_score(all_labs, all_preds), 4) \n",
    "    precision = round(precision_score(all_labs, all_preds, zero_division = 0), 4) # (TP / TP+FP)\n",
    "    recall = round(recall_score(all_labs, all_preds, zero_division = 0), 4) # true positive rate (TP / FN+TP)\n",
    "\n",
    "    if print_output:\n",
    "        print(confusion_matrix(all_labs, all_preds), end = '\\n\\n')\n",
    "        print('Accuracy:', accuracy) \n",
    "        print('Precision:', precision) \n",
    "        print('Recall:', recall)\n",
    "        return None\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "################################\n",
    "## MODEL\n",
    "################################\n",
    "class Anomaly_Detector(nn.Module):\n",
    "    def __init__(self, n_features, seq_length, vocab_size, batch_size, n_layer = 1, bidirectinoal = False, drop_prob = 0):\n",
    "        super().__init__()\n",
    "        # Params\n",
    "        self.n_features = n_features\n",
    "        self.seq_len = seq_length\n",
    "        self.vocab = vocab_size\n",
    "        self.n_layers = 2\n",
    "        self.hidden_dim = 64\n",
    "        self.bidir = 2 if bidirectinoal==True else 1\n",
    "        self.drop = drop_prob\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Layers\n",
    "        #self.embedding = nn.Embedding(self.vocab, 64)\n",
    "        self.lstm = nn.LSTM(input_size = self.n_features, hidden_size = self.hidden_dim,\n",
    "                            num_layers = self.n_layers, batch_first = True,\n",
    "                            dropout = drop_prob, bidirectional = bidirectinoal)\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_dim*self.bidir, 1) # multiply hidden by 2 if using bidirectinoality\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        sequences = sequences.to(DEVICE) # [batch_size, seq_len] \n",
    "        lstm_out, (hidden, cell) = self.lstm(sequences)  \n",
    "        # lstm_out = [batch_size, seq_length, hidden_dim * num_directions]\n",
    "        # hidden = [num layers * num directions,  batch size, hidden_dim]\n",
    "        # cell = [num layers * num directions, batch size, hidden_dim]        \n",
    "        \n",
    "        # if using a bidirectional lstm, concatenate the final forward and backward hidden layers \n",
    "        if self.bidir==1:\n",
    "            # if there's more than 1 LSTM layer keep only the last one\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "        elif self.bidir==2: \n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "\n",
    "        return self.sigmoid(self.linear(hidden)).reshape(-1)\n"
   ]
  },
  {
   "source": [
    "## Initialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## ARCHITECTURAL PARAMETERS\n",
    "################################\n",
    "N_FEATURES = 2          # features: time differences and ID sequences\n",
    "SEQ_LEN = 100           # sequence length\n",
    "VOCAB_SIZE = n_events   # number of unique IDs \n",
    "N_LAYERS = 2            # LSTM layers\n",
    "BIDIRECTIONAL = True    # directionality\n",
    "DROPOUT = 0\n",
    "\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.00001 \n",
    "CLIP = 5\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "## INITIALIZE MODEL\n",
    "model = Anomaly_Detector(N_FEATURES, SEQ_LEN, VOCAB_SIZE, BATCH_SIZE, N_LAYERS, BIDIRECTIONAL, DROPOUT)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "## LOSS AND OPTIMIZER\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "## DEFINE TRAINING + TESTING FUNCTION\n",
    "################################\n",
    "def training_function():\n",
    "    print('\\nSTARTING TRAINING\\n')\n",
    "    start_time = time.time()\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        print(f'Starting Epoch: {epoch+1}')\n",
    "        for batch_idx, batch_data in enumerate(train_loader):\n",
    "            inpt, labs = batch_data[0], batch_data[1]\n",
    "            # convert datatypes to prevent dtype bug\n",
    "            inpt, labs = inpt.float().to(DEVICE), labs.float().to(DEVICE)\n",
    "\n",
    "            # clear gradients\n",
    "            optimizer.zero_grad() \n",
    "            logits = model(inpt) # logits are the final hidden states)\n",
    "            cost = criterion(logits, labs) # .squeeze()\n",
    "            cost.backward()\n",
    "\n",
    "            # Use clip_grad_norm to prevent exploding gradients\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            # logging\n",
    "            if not batch_idx % 100:\n",
    "                print (f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                       f'BCE Cost: {cost:.4f}')\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            model.eval()\n",
    "            a, p, r = compute_binary_accuracy(model, train_loader, DEVICE)\n",
    "            a2, p2, r2 = compute_binary_accuracy(model, val_loader, DEVICE)\n",
    "            print(f'Epoch Completed: '\n",
    "                  f'\\n\\twith training: {a:.3f}% - {p:.3f}% - {r:.3f}%'\n",
    "                  f'\\n\\tand validation: {a2:.3f}% - {p2:.3f}% - {r2:.3f}%')\n",
    "\n",
    "        print(f'\\tTime elapsed: {(time.time() - start_time)/60:.2f} min\\n')\n",
    "\n",
    "    ## Final Test Accuracy\n",
    "    print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "    print('----------------------------------------------')\n",
    "    print('Final Test Accuracy/Precision/Recall : ', compute_binary_accuracy(model, test_loader, DEVICE))\n",
    "    print('----------------------------------------------')\n",
    "\n",
    "training_function()"
   ]
  },
  {
   "source": [
    "## Saving Models\n",
    "\n",
    "*Performance metrics refer only to results from the test set.*\n",
    "\n",
    "**Features** | **model1** | **model2** | **model3**\n",
    "---         | ---       | ---       | ---\n",
    "seq_len     | 100       | 100       | 100\n",
    "learn_rate  | 1e-5      | **1e-4**  | **1e-5**\n",
    "epochs      | 50        | **25**    | **50**\n",
    "batch       | 256       | 256       | 256\n",
    "layers      | 2         | 2         | 2\n",
    "bidir       | True      | True      | True\n",
    "dropout     | 0.5       | **0**     | **0**\n",
    "hidden      | 64        | 64        | 64\n",
    "accuracy    | 0.981     | 0.9872    | 0.9936\n",
    "precision   | 0.993     | 0.9993    | 0.9965\n",
    "recall      | 0.9731    | 0.9609    | 0.9835\n",
    "train_time  | 15 min    | 8 min     | 16 min\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Model/CarHacking_models/'\n",
    "\n",
    "model = 'model3.pt'\n",
    "\n",
    "# Save\n",
    "torch.save(Anomaly_Detector, path + model)\n",
    "\n",
    "# Load\n",
    "name = 'name here'\n",
    "#model = Net()\n",
    "#model.load_state_dict(torch.load(path + name))\n",
    "#model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "b49af92716124a3dcdffffc9745ca4adb6a99ad9a5084f8f6ea1cee1a8d52ff7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}